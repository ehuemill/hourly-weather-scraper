{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Historical Weather Webpage from Weather Underground\n",
    "\n",
    "The Goal of the following section is to download the appropriate webpages that contain the historical weather data.  It was originally written by someone at 538 and I downloaded it as a way to learn how to scrape the web for data.  \n",
    "\n",
    "- It downloads the intire html webpage in the next code block\n",
    "- then opens it\n",
    "- looks for the data you want on the webpage using tags\n",
    "- Finally it writes that data to a file in the next cell as a csv file for later use.\n",
    "\n",
    "This is my first data science individual project, so hopefully I dont royally screw it up!\n",
    "\n",
    "\n",
    "The end goal is to have a csv file that has the hourly historical weather data from weather underground for a given range of dates.  It should include the date and time of the data as well as all of the columns that weather underground has for each hour.\n",
    "\n",
    "enjoy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Scraping the Web for the Webpages with Weather Data in them\n",
    "## 1a) import the libraries we will need, and make date variables\n",
    "\n",
    "Start by making some functions that will be used for downloading so that the code we write later on will be less of a big block of text, and more of simple names of functions that are called.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#define the list of stations to look at\n",
    "stations = ['KCMI',\n",
    "           'KBOS']\n",
    "\n",
    "#set up starting date\n",
    "starting_year = 2017\n",
    "starting_month = 10\n",
    "starting_day = 31\n",
    "\n",
    "#set up ending date\n",
    "ending_year = 2017\n",
    "ending_month = 11\n",
    "ending_day = 4\n",
    "\n",
    "\n",
    "\n",
    "#putting the dates into variales that can be used\n",
    "start_date = datetime(year=starting_year, month = starting_month, day = starting_day)\n",
    "end_date = datetime(year=ending_year,month=ending_month, day=ending_day)\n",
    "\n",
    "current_date = start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) Func: Formating the URL given a station and date\n",
    "\n",
    "\n",
    "The first thing I want to create a function that  will format and create the string that is the URL to download\n",
    "\n",
    "The main purpose of splitting this up into more and more cells is so that it is easier for someone else to read, or for me to remember what I was thinking when I was doing.  It also works well as a rubber duck dbugging method for me.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wundgnd_hourly_URLgen (station, current_date):\n",
    "\n",
    "    '''\n",
    "    the input for this will be a time object with the year, month, day and a time of all zeros.  \n",
    "    Having the time be all zeros will be important for generating time stamps for each row of data from the table later on\n",
    "\n",
    "    the output will be a string that is the URL of the weather underground page that we want to have downlaoded\n",
    "    '''\n",
    "    #input the base URL that we will use to get the data\n",
    "    lookup_URL = 'http://www.wunderground.com/history/airport/{}/{}/{}/{}/DailyHistory.html'\n",
    "        \n",
    "    #generate the url for this location and date\n",
    "    formatted_lookup_URL = lookup_URL.format(station,\n",
    "                    current_date.year,current_date.month,current_date.day)\n",
    "    return formatted_lookup_URL\n",
    "    \n",
    "#URL_to_write = wundgnd_hourly_URLgen('CMI', start_date )\n",
    "#print(URL_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that looks like what we want it to do.  This will only work for the specific URL that we are dealing with.  \n",
    "to scrape a different webpage (that is still just time formated) all you need to do is figure out where the\n",
    "date/location/other variable needs to go and format it in that way.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1c) Func: Take in a URL and save the webpage\n",
    "\n",
    "the nest step in the process is to take the URL that was just generated, find the page, and download it.  \n",
    "Lets write a function to do this so that the actual running of the code is less brain intensive for us.\n",
    "\n",
    "This will be for a specific date, and a specific airport because that is how the webpages are organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "URL_to_write = wundgnd_hourly_URLgen('CMI', start_date )\n",
    "\n",
    "def wundgnd_hourly_pagesave (formatted_lookup_URL,station, current_date):\n",
    "    '''  The goal of this function is to take in a URL and save the file to a folder named with the station abreviation\n",
    "    \n",
    "    the input should be a string that is a valid URL, a station name, and a date object called current_date\n",
    "    \n",
    "    there will be no formal output, but the result should be an html file saved in the folder we want it saved into\n",
    "    \n",
    "    BE CAREFUL\n",
    "    The open as writing will just overwrite any file you have in there.  This means that every time it will overwrite\n",
    "    whatever you have in there with that file name.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #pull the html file in that is at the url that we want.\n",
    "    html = urlopen(formatted_lookup_URL).read().decode('utf-8')\n",
    "\n",
    "    #generate the file name for the url to be saved\n",
    "    out_file_name = '{}/html_files/{}-{}-{}.html'.format(station, current_date.year,\n",
    "                                                  current_date.month,\n",
    "                                                  current_date.day)\n",
    "    #open the file just generated to write, which overwrites any old files you might have had.\n",
    "    with open(out_file_name, 'w') as out_file:\n",
    "        out_file.write(html)\n",
    "        \n",
    "    #print('Wrote file',out_file_name )\n",
    "    \n",
    "#testing the function\n",
    "#wundgnd_hourly_pagesave(URL_to_write,'CMI',current_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d) Func: Downloading all the Webpages we Need\n",
    "\n",
    "now that we have defined the functions for generating the URL and downloading the page,\n",
    "the next step is to iterate through the dates and stations that we want to download info for\n",
    "\n",
    "It should be much shorter than the older version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KCMI/html_files/\n",
      "\n",
      "( 2017-11-05 21:10:10 ) Working on KCMI data from  2017-10-31 00:00:00\n",
      "\n",
      "( 2017-11-05 21:10:11 ) Working on KCMI data from  2017-11-01 00:00:00\n",
      "\n",
      "( 2017-11-05 21:10:13 ) Working on KCMI data from  2017-11-02 00:00:00\n",
      "\n",
      "( 2017-11-05 21:10:15 ) Working on KCMI data from  2017-11-03 00:00:00\n",
      "KBOS/html_files/\n",
      "\n",
      "( 2017-11-05 21:10:17 ) Working on KBOS data from  2017-10-31 00:00:00\n",
      "\n",
      "( 2017-11-05 21:10:18 ) Working on KBOS data from  2017-11-01 00:00:00\n",
      "\n",
      "( 2017-11-05 21:10:20 ) Working on KBOS data from  2017-11-02 00:00:00\n",
      "\n",
      "( 2017-11-05 21:10:22 ) Working on KBOS data from  2017-11-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def scrape_station(station, start_date, end_date):\n",
    "    '''\n",
    "    This function scrapes the weather data web pages from wunderground.com\n",
    "    for the station you provide it in the date range provided.\n",
    "\n",
    "    You can look up your city's weather station by performing a search for\n",
    "    it on wunderground.com then clicking on the \"History\" section.\n",
    "    The 4-letter name of the station will appear on that page.\n",
    "    '''\n",
    "\n",
    "    #initialize the loop at the variable at the starting day\n",
    "    current_date = start_date\n",
    "\n",
    "    # See if a directory exists in the local folder, and if it doesnt, make one\n",
    "    saving_folder = station +'/html_files/'\n",
    "    #print(saving_folder)\n",
    "    if os.path.isdir(station) != True :\n",
    "        os.mkdir(station)\n",
    "        if os.path.isdir(saving_folder) != True:\n",
    "            os.mkdir(saving_folder)\n",
    "            \n",
    "    print(saving_folder)\n",
    "    #Iterate through the days to download each webpage\n",
    "    while current_date != end_date:\n",
    "\n",
    "        print('\\n(',datetime.now().strftime('%Y-%m-%d %H:%M:%S'),') Working on',station, 'data from ', current_date)\n",
    "\n",
    "        #generate the URL to look up\n",
    "        URL_to_write = wundgnd_hourly_URLgen (station, current_date)\n",
    "\n",
    "        #generate the file name for the url to be saved\n",
    "        wundgnd_hourly_pagesave(URL_to_write,station,current_date)\n",
    "        \n",
    "        #wait a second and then iterate the day.  Dont want to get blocked!\n",
    "        time.sleep(1) \n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "\n",
    "# Run the function to scrape the station we are interested in\n",
    "for element in stations:\n",
    "    #print(element)\n",
    "    scrape_station(element, start_date, end_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now we have each webpage downlaoded and the code is easy to read and understand.  \n",
    "\n",
    "Now would be a good time to check to see that they downloaded to a place that you think they should have downloaded to.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Pulling the Data off of the Downloaded Webpages\n",
    "\n",
    "## 2a) Func: Pull in the webpage and output a data structure with all the data in it\n",
    "\n",
    "For the next step, after downloading all of the webpages to the local server, we want to pull the data off of the html formatted wepage.   This will require going through each of the html files and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wundgnd_hourly_tableextract (file_in_name):\n",
    "\n",
    "    '''\n",
    "    The goal of this function is to intake a file name (that presumably exists) and output the html from the table\n",
    "    that we are actually interested in (the one with the historical hourly weather data in it)\n",
    "    \n",
    "    input: File name as a string\n",
    "    \n",
    "    output: The raw table html without formatting or extracting data\n",
    "    \n",
    "    '''\n",
    "    from datetime import datetime, timedelta\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.request import urlopen\n",
    "    \n",
    "    with open(file_in_name) as in_file:\n",
    "                \n",
    "        #extract the html using Beautiful Soup into a variable called soup\n",
    "        soup = BeautifulSoup(in_file.read(), 'html.parser')\n",
    "        \n",
    "        #print(soup)\n",
    "        #Find the table, and define the table_html variable so we can use it\n",
    "        page_html =  soup.findAll(\"div\", {\"class\":\"high-res\"})\n",
    "        #print(page_html)\n",
    "        \n",
    "        table_html = page_html[0]\n",
    "        #print(table_html)        \n",
    "        data_array = []\n",
    "        #in the table that is html formatted, find each row via its class and its label\n",
    "        row_html = table_html.findAll('tr',{\"class\" : \"no-metars\"})\n",
    "        #print(row_html)\n",
    "        for row in row_html:\n",
    "            \n",
    "            #print(row.text.split())\n",
    "            data_array.append(row.text.split())\n",
    "            \n",
    "        #print(data_array)    \n",
    "        \n",
    "        return data_array\n",
    "    \n",
    "file_in_name = '{}/html_files/{}-{}-{}.html'.format(stations[0], current_date.year,\n",
    "                                                  current_date.month,\n",
    "                                                  current_date.day)\n",
    "data = wundgnd_hourly_tableextract(file_in_name)\n",
    "\n",
    "#print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the output that is a list of lists of strings of each of the rows of the table from the page.  Upward and Onward!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "\n",
    "#for i in range(len(data)):\n",
    "    #print(data[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Time Time Time, time to figure it out\n",
    "\n",
    "Once we get the data imported, we want to be able to note what time each of the rows are from.  Since the time \n",
    "from the data will be a string, lets write a function that will change from hh:mm am/pm to a time object we can add to the date and change the time stamp for that data column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:53\n",
      "2017-10-31 00:00:00\n",
      "2017-10-31 21:53:00\n"
     ]
    }
   ],
   "source": [
    "def hhmm2time (string_hh_mm, ampm = 'am'):\n",
    "    \n",
    "    \"\"\" the goal of this is to make a program that intakes a time that is a string and can ouput\n",
    "    a time in hours and minutes that can be added to the time variables.  \n",
    "    \n",
    "    The best way to do that might be tomake something that is a time difference in of itself.  \n",
    "    Ill start working on doign that.  \n",
    "    \n",
    "    The imput should be a time of the format 'hh:mm'\n",
    "        - it does not matter if there is 1 or 2 hour or minute digits\n",
    "        - The defaul is to have the time in 24 hour time rather than 12 hour\n",
    "        - If the time is in 12 hour, include am or pm as the second input and it will adjust for it\n",
    "    \n",
    "    The output will be a time delta object that can be added to the curren time to have\n",
    "        the correct time stamp in the data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #split the time up into hours and minutes\n",
    "    [hours , minutes] = string_hh_mm.split(':')\n",
    "    \n",
    "    #adjust for 12 hr vs 24 hour time and define the output variable\n",
    "    if ampm == 'pm': \n",
    "        output = timedelta(hours = (int(hours)+12), minutes = int(minutes))\n",
    "    else:\n",
    "        output = timedelta(hours = (int(hours)), minutes = int(minutes))\n",
    "    \n",
    "    return output\n",
    "\n",
    "#testing the function\n",
    "string_hh_mm = '9:53'\n",
    "\n",
    "print(string_hh_mm)\n",
    "print(current_date)\n",
    "\n",
    "print(current_date + hhmm2time(string_hh_mm,'pm'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b) Cleaning and Formating the Data We want from the Table\n",
    "\n",
    "So this is the real nitty gritty part of data science, where you have imported the data, its in some format, and we need to figure out how to make sense of the whole thing.  For this data set the biggest porblem is that the second column is wind chill, which is not listesd for every every day, and not even neccearily listed for every hour.  Also the fact that the units on each of the numbers is broken out into another column (which could be useful...)\n",
    "\n",
    "So here goes, to start, I will just make 3 data pieces, and pull them off so that I can plot them.  \n",
    "\n",
    "- Time (as hh:mm)\n",
    "- Time of Day (as am or pm)\n",
    "- Temperature (as dd.d)\n",
    "- What ever the place after temperature is\n",
    "\n",
    "\n",
    "Luckey for me, the main thing I am looking for (temperature vs time) are the first two columns, and they should work without a problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time Stamp', 'AirTemp(F)', 'AirTemp(c)']\n",
      "['yyyy-mm-dd hh:mm:ss', 'F', 'C']\n",
      "[['2017-10-31 12:53:00', 35.1, 1.8], ['2017-10-31 01:53:00', 37.9, 3.3], ['2017-10-31 02:53:00', 37.9, 3.3], ['2017-10-31 03:53:00', 37.0, 2.8], ['2017-10-31 04:53:00', 37.0, 2.8], ['2017-10-31 05:53:00', 35.1, 1.8], ['2017-10-31 06:53:00', 30.9, -0.6], ['2017-10-31 07:53:00', 30.0, -1.1], ['2017-10-31 08:53:00', 35.1, 1.8], ['2017-10-31 09:53:00', 37.9, 3.3], ['2017-10-31 10:53:00', 39.0, 3.9], ['2017-10-31 11:53:00', 39.9, 4.4], ['2017-10-31 12:53:00', 42.1, 5.7], ['2017-10-31 01:53:00', 41.0, 5.0], ['2017-10-31 02:53:00', 42.1, 5.7], ['2017-10-31 03:53:00', 43.0, 6.2], ['2017-10-31 04:53:00', 42.1, 5.7], ['2017-10-31 05:53:00', 39.9, 4.4], ['2017-10-31 06:53:00', 39.0, 3.9], ['2017-10-31 07:53:00', 37.9, 3.3], ['2017-10-31 09:53:00', 37.0, 2.8], ['2017-10-31 10:53:00', 37.0, 2.8], ['2017-10-31 11:53:00', 37.9, 3.3]]\n"
     ]
    }
   ],
   "source": [
    "#print(data[0])\n",
    "\n",
    "def wundgnd_hourly_datacleaning (current_date, data):\n",
    "    '''\n",
    "    The goal of this function is to take the string of srings that wundgnd_hourly_tableextract outputs \n",
    "    (or whatever other data structure that eventually gets changed to) and make variables for each \n",
    "    value that we are interested in (right now just time, am/pm, temperature, the next thing after temp)\n",
    "    \n",
    "    the input : a list of a list of strings or some other data structure (pandas data fram eventually?)\n",
    "    \n",
    "    output : list of lists that is a regular shape (square) and has the values we want in it\n",
    "            Another output should be the header file that we want the file to have.  \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    import numpy as np\n",
    "    import math\n",
    "    #print(data[0])\n",
    "    \n",
    "    \n",
    "    #creating the header for the data file\n",
    "    \n",
    "    header = ['Time Stamp', 'AirTemp(F)','AirTemp(c)']\n",
    "    units = ['yyyy-mm-dd hh:mm:ss', 'F', 'C']\n",
    "    data_cleaned = []\n",
    "    \n",
    "    for row in data[0:]:\n",
    "        \n",
    "        #print(row)\n",
    "        #row is a list of strings that is a row of the weather data table.  Aka all data for a given time\n",
    "\n",
    "        #define each of the data variables that we want to output\n",
    "        data_hhmm_str = row[0]\n",
    "        data_ampm = row[1]\n",
    "        date_and_time = str(current_date + hhmm2time(data_hhmm_str,data_ampm))\n",
    "                \n",
    "        data_temp_f = float(row[2])\n",
    "        data_temp_c = math.ceil((10.*(float(data_temp_f)-32)*5/9))/10\n",
    "        \n",
    "        #print(data_time , data_ampm , data_temp_f, data_temp_c)\n",
    "        \n",
    "        data_list = [date_and_time, data_temp_f, data_temp_c]\n",
    "        #print(data_list)\n",
    "        \n",
    "        # data_str = \n",
    "        data_cleaned.append(data_list)\n",
    "    \n",
    "    return [header, units, data_cleaned]\n",
    "[data_header, data_units, data_list] = wundgnd_hourly_datacleaning (current_date, data)\n",
    "\n",
    "print(data_header)\n",
    "print(data_units)\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so that is a wrap on the wundgnd_hourly_datacleaning function that takes in a list of lists, and pulls out the values we want, creates a header (that is defined in the function) and outputs a list of lists (or some other data structure) that we can use to manipulate the data and save it to a csv file.  \n",
    "\n",
    "Nice Work Team!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2017-10-31 12:53:00', 35.1, 1.8], ['2017-10-31 01:53:00', 37.9, 3.3], ['2017-10-31 02:53:00', 37.9, 3.3], ['2017-10-31 03:53:00', 37.0, 2.8], ['2017-10-31 04:53:00', 37.0, 2.8], ['2017-10-31 05:53:00', 35.1, 1.8], ['2017-10-31 06:53:00', 30.9, -0.6], ['2017-10-31 07:53:00', 30.0, -1.1], ['2017-10-31 08:53:00', 35.1, 1.8], ['2017-10-31 09:53:00', 37.9, 3.3], ['2017-10-31 10:53:00', 39.0, 3.9], ['2017-10-31 11:53:00', 39.9, 4.4], ['2017-10-31 12:53:00', 42.1, 5.7], ['2017-10-31 01:53:00', 41.0, 5.0], ['2017-10-31 02:53:00', 42.1, 5.7], ['2017-10-31 03:53:00', 43.0, 6.2], ['2017-10-31 04:53:00', 42.1, 5.7], ['2017-10-31 05:53:00', 39.9, 4.4], ['2017-10-31 06:53:00', 39.0, 3.9], ['2017-10-31 07:53:00', 37.9, 3.3], ['2017-10-31 09:53:00', 37.0, 2.8], ['2017-10-31 10:53:00', 37.0, 2.8], ['2017-10-31 11:53:00', 37.9, 3.3]]\n",
      "['KCMI', 'KBOS']\n"
     ]
    }
   ],
   "source": [
    "#First lest see what the data looks like.  \n",
    "\n",
    "print(data_list)\n",
    "print(station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Looping Through days and Saving the Data to a file\n",
    "\n",
    "## 3a) taking in the data, and saving it to a file\n",
    "\n",
    "Ok, so we have the data that we are interested in, and we have dates and times, and temperatures.  Now its time to either do analyiss on it, or save it to a file.  Lets work on making a function that saves the data to a file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Putting it all together\n",
    "\n",
    "Now that we have all the pieces in place, we need to write a for loop that will iterate through all of the dates and locations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  KCMI\n",
      "2017-10-31 00:00:00\n",
      "2017-11-01 00:00:00\n",
      "2017-11-02 00:00:00\n",
      "2017-11-03 00:00:00\n",
      "Working on  KBOS\n",
      "2017-10-31 00:00:00\n",
      "2017-11-01 00:00:00\n",
      "2017-11-02 00:00:00\n",
      "2017-11-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for station in stations:\n",
    "    print('Working on ',station)\n",
    "    current_date = start_date\n",
    "    \n",
    "    with open('{}/weather_hourly_{}_{}-{}-{}_to_{}-{}-{}.csv'.format(station,station,current_date.year,\n",
    "                                                             current_date.month,current_date.day,end_date.year,\n",
    "                                                             end_date.month,end_date.day), 'w') as out_file:\n",
    "        \n",
    "        #convert the header to a comma separated string so it can be written to the file.\n",
    "        header_to_write = \",\".join (map(str,data_header))+'\\n'\n",
    "        out_file.write(header_to_write)\n",
    "        \n",
    "        units_to_write = \",\".join(map(str,data_units))+'\\n'\n",
    "        out_file.write(units_to_write)  \n",
    "            \n",
    "            \n",
    "          \n",
    "        while current_date != end_date:\n",
    "            #First pull in the data off of the webpages that have already been downloaded\n",
    "            print(current_date)\n",
    "            \n",
    "            file_in_name = '{}/html_files/{}-{}-{}.html'.format(stations[0], current_date.year,\n",
    "                                                  current_date.month,\n",
    "                                                  current_date.day)\n",
    "            \n",
    "            data = wundgnd_hourly_tableextract(file_in_name)\n",
    "        \n",
    "            #make the data strucutres that you want with the data cleaning function\n",
    "            [data_header, data_units, data_list] = wundgnd_hourly_datacleaning (current_date, data)\n",
    "            \n",
    "              \n",
    "            #opening the webpage that the information is in according to the labels from the other function\n",
    "            with open('{}/html_files/{}-{}-{}.html'.format(station, current_date.year, \n",
    "                                                current_date.month, current_date.day)) as in_file:\n",
    "                for row in data_list:\n",
    "                    data_to_write =  \",\".join(map(str,row))+'\\n'\n",
    "                    #print(data_to_write)\n",
    "                    out_file.write(data_to_write)\n",
    "                    #print(data_to_write)\n",
    "    \n",
    "         \n",
    "            #iterate the day 1 day\n",
    "            current_date += timedelta(days=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
